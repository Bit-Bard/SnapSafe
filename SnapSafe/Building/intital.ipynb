{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de50f223-6bdb-4d07-93d1-8314f7e32a9d",
   "metadata": {},
   "source": [
    "**photo->text->OCR->Extracted text-->Chemical Extraction-> predict through csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a88a8-a23a-4048-8fbe-933ca48e13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"majority_ensemble.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546c395a-6ed8-4936-bd00-a0cbb254f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import pubchempy as pcp\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da76c39-3b43-4b3c-a22e-fd765c3ebe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\dhruv\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe' #tesseract path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68906eb1-d1a7-49f6-9fa4-44764c3a6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image then convert it into \n",
    "image = cv2.imread('Screenshot 2025-06-08 161620.png')  \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# remove noise and improve clarity\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84efb6da-e836-4b14-8e9c-507e72b171d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Ingredients:\n",
      "964\n"
     ]
    }
   ],
   "source": [
    "#Ocr: it will extract text from img\n",
    "text = pytesseract.image_to_string(gray)\n",
    "\n",
    "print(\"Extracted Ingredients:\")\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d6fdaf-1403-4063-8173-87714d261353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, digits, extra whitespace\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.strip().lower()\n",
    "    return text\n",
    "preprocess_text(text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d0083b-d08a-4a8f-93de-6d6e84fa3883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CALIFORNIA PROPOSITION 65\\nWarning: This product contoins nicotine, o chemical known to the\\nstote of Colifornio to couse birth defects or other reproductive horm\\n\\nTngr “ym Silas Hota. Nicotine, FCC Grade Vegetable Glycerin,\\n\\n[etre Fos, lv Ac. Westin conten 6 8 per\\ncontri\\n\\nMade in China.\\nFlavors mode in USA\\n©2012 LOEC, in.\\n\\nblu™ ond blu eCigs® are trademarks of Lorillord Technologies, Inc.\\n\\n1 serving per pack\\nServing size 1 pack (32.35)\\ncesar appara\\n\\nCalories 150\\n\\nTrans Fat 09\\nCholesterol m9\\nSodium 1059 ot\\n\\nINGREDIENTS\\nMILK CHOCOLATE (SUGAR\\nCHOCOLATE MILK. COCOA\\nBL T T. SOY\\nLE\\n\\n(WHEAT FLOUR. NIACIN\\n\\nIRON, AMINE M\\n\\nRIBOFLAVIN, FOLIC ACID)\\n\\nMODIFIED SAGO STARCH. SAI\\n\\nSOYBEAN OIL, CORN SYRUP.\\n\\nBARLEY MALT EXTRACT\\n\\nLEAVENING (BAKING SODA. YEAS\\n\\nAND/OR AMMONIUM\\n\\nBICARBONATE)]. LESS THAN 2\\n\\nCORNSTARCH, CORN SYRUP.\\n\\nDEXTRIN. SALT. COLORING\\n\\n(INCLUDES BLUE 1 LAKE, RED 40.\\nLLOW 6, YELLOW S$. BLUE 1, RED\\n\\n40 LAKE, YELLOW 6 LAK!\\n\\nSLAKE\\n\\nCARNAUBA WAX. GUM ACACIA\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b3fc0a4-197b-462e-b122-c030480f5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhruv\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhruv\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhruv\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load(\"Tuned_model.joblib\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.joblib\")\n",
    "\n",
    "# model = joblib.load(\"Tuned_model.joblib_recent\")\n",
    "# vectorizer = joblib.load(\"tfidf_vectorizer.joblib_recent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5ae024-dde4-4b12-8489-385110a3a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_product_category(text):\n",
    "    clean_text = preprocess_text(text)\n",
    "    X_vec = vectorizer.transform([clean_text])\n",
    "    predicted_label = model.predict(X_vec)[0]\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc67beee-4f90-4c0b-8c47-7b781e83f89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: 2\n"
     ]
    }
   ],
   "source": [
    "ocr_output_text = \"Aqua, Glycerin, Paraben, Fragrance\"\n",
    "ocr_output2 = \"Calcium Carbonate, Microcrystalline Cellulose, Talc, Magnesium Stearate\"\n",
    "\n",
    "predicted_category = predict_product_category(text)\n",
    "print(\"Predicted Category:\", predicted_category)\n",
    "# chemical_list = [\"Paraben\", \"Fragrance\", \"Glycerin\"]\n",
    "# for chem in chemical_list:\n",
    "#     score = get_contextual_harm_score(chem, predicted_category)\n",
    "#     print(f\"{chem} in {predicted_category} → Harm Score: {score}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b66ff6-3ebd-432a-b461-e6b645b9b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for others \n",
    "\n",
    "def predict_category_with_fallback(text, model, vectorizer, threshold=0.45):\n",
    "    clean_text = preprocess_text(text)\n",
    "    X_vec = vectorizer.transform([clean_text])\n",
    "    \n",
    "    proba = model.predict_proba(X_vec)[0]\n",
    "    max_confidence = np.max(proba)\n",
    "    predicted_label = model.classes_[np.argmax(proba)]\n",
    "\n",
    "    # Fallback to \"others\" if confidence is too low\n",
    "    if max_confidence < threshold:\n",
    "        return \"others\",proba\n",
    "    return predicted_label,proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc25e9fd-c656-49a6-aa19-d2d39a086753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: others\n"
     ]
    }
   ],
   "source": [
    "ocr_output = \"Aqua, Glycerin, Paraben, Fragrance\"\n",
    "ocr_output2 = \"Calcium Carbonate, Microcrystalline Cellulose, Talc, Magnesium Stearate\"\n",
    "\n",
    "category, proba = predict_category_with_fallback(ocr_output2, model, vectorizer)\n",
    "print(\"Predicted Category:\", category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1045f-5756-45ef-bb09-ee40f8d9099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Scores: {0: 0.06826293469599233, 1: 0.15197334223267034, 2: 0.05653453602289769, 3: 0.16256544994690067, 4: 0.1473550651538402, 5: 0.2140389148476442, 6: 0.10310496088536648, 7: 0.09616479621468824}\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence Scores:\", dict(zip(model.classes_, proba)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d278785-efde-4422-b6ba-b25684985bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##chemical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "314aba10-c83c-4d36-91cb-b611f3837576",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`pydantic:ConstrainedStr` has been removed in V2.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#we will use NLp Spacy for Chemical extraction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_ner_bc5cdr_md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# text = \"Sodium Lauryl Sulfate, Propylparaben, Aloe Vera\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\__init__.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\attributeruler.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\pipeline\\pipe.pyx:1\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\tokens\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspan\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Span\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\tokens\\doc.pyx:36\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\schemas.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, ValidationError, validator, create_model\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrictStr, StrictInt, StrictFloat, StrictBool, ConstrainedStr\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMetaclass\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer, ConfigValidationError, Model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\__init__.py:426\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m    424\u001b[0m dynamic_attr \u001b[38;5;241m=\u001b[39m _dynamic_imports\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m package, module_name \u001b[38;5;241m=\u001b[39m dynamic_attr\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\_migration.py:302\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor more details.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` has been removed in V2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28mglobals\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m:\n",
      "\u001b[1;31mPydanticImportError\u001b[0m: `pydantic:ConstrainedStr` has been removed in V2.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error"
     ]
    }
   ],
   "source": [
    "#we will use NLp Spacy for Chemical extraction\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "# text = \"Sodium Lauryl Sulfate, Propylparaben, Aloe Vera\"\n",
    "doc = nlp(text)\n",
    "\n",
    "chemicals = [ent.text for ent in doc.ents if ent.label_ == \"CHEMICAL\"]\n",
    "print(f\"Extracted chemicals: {chemicals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e9b9e-4add-4d13-b99d-66a538483e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chemicals now we filtered chemicals : chemicals no noise\n",
    "import pubchempy as pcp\n",
    "\n",
    "raw_chemicals = [ent.text for ent in doc.ents if ent.label_ == \"CHEMICAL\"]\n",
    "\n",
    "# Validate with PubChem\n",
    "def is_valid_chemical(name):\n",
    "    try:\n",
    "        result = pcp.get_compounds(name, 'name')\n",
    "        return len(result) > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Filter only valid chemical names\n",
    "filtered_chemicals = [chem for chem in raw_chemicals if is_valid_chemical(chem)]\n",
    "\n",
    "print(\"Extracted Chemicals:\", filtered_chemicals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa11be1-7f9a-4f95-81a6-c04802e9dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #we have to use model here for prediction after getting chemicals \n",
    "\n",
    "# predicted_category = predict_product_category(filtered_chemicals)\n",
    "# print(\"Predicted Category:\", predicted_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930de2b9-2135-44d7-8c08-ea2c87f536b0",
   "metadata": {},
   "source": [
    "**harmfull prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb4201-008f-47d3-89bc-6a682da1114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem=pd.read_csv(\"Chemicals_label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "941b139f-74d6-48a4-8363-3cdeb4839552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for harmfull chemicals : among chemicals which one is chemical\n",
    "def get_harm_info(chemical_name):\n",
    "    row=chem[chem[\"chemical_name\"].str.lower()==chemical_name.lower()]\n",
    "\n",
    "    if not row.empty:\n",
    "        harm_score=int(row[\"harm_score\"].values[0])\n",
    "        #no alternative values\n",
    "        return harm_score\n",
    "\n",
    "    else:\n",
    "        #chemicals name not found return Safe \n",
    "        return 0,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa6a2331-d900-4acb-a7cd-471236ed89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical: Formaldehyde\n",
      "Harmfulness Score: 95%\n",
      "Chemical: Ethanolamine\n",
      "Harmfulness Score: 0%\n",
      "Average Harmfulness Score: 95.0%\n"
     ]
    }
   ],
   "source": [
    "#integration with chemical \n",
    "overall = []\n",
    "count = 0\n",
    "\n",
    "for chemical in filtered_chemicals:\n",
    "    harm_score = get_harm_info(chemical)\n",
    "\n",
    "    #  harm_score is a tuple \n",
    "    if isinstance(harm_score, tuple) and len(harm_score) > 0:\n",
    "        harm_score_value = harm_score[0]  # Extract the first element of the tuple\n",
    "    else:\n",
    "        harm_score_value = harm_score  # In case it's already an integer or float\n",
    "\n",
    "    if harm_score_value > 0:\n",
    "        overall.append(harm_score_value)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"Chemical: {chemical}\")\n",
    "    print(f\"Harmfulness Score: {harm_score_value}%\")\n",
    "\n",
    "if count > 0:\n",
    "    average = sum(overall) / count\n",
    "    print(f\"Average Harmfulness Score: {average}%\")\n",
    "else:\n",
    "    print(\"No harmful chemicals found to calculate an average.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c31fea12-2946-487d-a535-31971ac5740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai detection#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48cc3d0e-d36d-49c8-87e7-405c4e2df9d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'extended_product_dataset.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m output_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct.csv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reading the text file\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_txt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m txtfile:\n\u001b[0;32m      8\u001b[0m     lines \u001b[38;5;241m=\u001b[39m txtfile\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Writing to the CSV file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'extended_product_dataset.txt'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_txt_file = 'extended_product_dataset.txt'\n",
    "output_csv_file = 'product.csv.csv'\n",
    "\n",
    "# Reading the text file\n",
    "with open(input_txt_file, 'r') as txtfile:\n",
    "    lines = txtfile.readlines()\n",
    "\n",
    "# Writing to the CSV file\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for line in lines:\n",
    "        # Assuming the values are separated by commas\n",
    "        row = line.strip().split(',')\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Text file has been converted to CSV successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e55bdc-5488-4f40-9d64-bdf3c8c8bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Photo → OCR → Text → Category Prediction → Chemicals Extraction → Contextual Harm Scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabe341f-1a59-48de-b7b2-d3fc26ee143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_output = \"nicotine, Nicotine, FCC, Glycerin, Cholesterol, Sodium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0589f81e-c239-4280-9593-50ec9f3f41d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ocr_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mothers\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_confidence\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_label, max_confidence\n\u001b[1;32m---> 20\u001b[0m category, confidence \u001b[38;5;241m=\u001b[39m predict_category_with_fallback(\u001b[43mocr_output\u001b[49m, model, vectorizer, label_encoder)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Category: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ocr_output' is not defined"
     ]
    }
   ],
   "source": [
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.lower().replace(\",\", \" \")\n",
    "\n",
    "def predict_category_with_fallback(text, model, vectorizer, label_encoder, threshold=0.45):\n",
    "    clean_text = preprocess_text(text)\n",
    "    X_vec = vectorizer.transform([clean_text])\n",
    "    \n",
    "    proba = model.predict_proba(X_vec)[0]\n",
    "    max_confidence = np.max(proba)\n",
    "    predicted_index = np.argmax(proba)\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    if max_confidence < threshold:\n",
    "        return \"others\", max_confidence\n",
    "    return predicted_label, max_confidence\n",
    "\n",
    "\n",
    "category, confidence = predict_category_with_fallback(ocr_output, model, vectorizer, label_encoder)\n",
    "print(f\"Predicted Category: {category} | Confidence: {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3d27b7f-285d-4973-866f-c7d56c57d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Aqua, Glycerin, Paraben, Fragrance, Dimethicone\n",
      " → Predicted Category: others | Confidence: 0.18\n",
      "\n",
      "Text: Sodium Benzoate, Citric Acid, Natural Flavours, Xanthan Gum, Sugar\n",
      " → Predicted Category: food | Confidence: 0.88\n",
      "\n",
      "Text: Water, Sodium Laureth Sulfate, Cocamidopropyl Betaine, PEG-40, Perfume\n",
      " → Predicted Category: personal_care | Confidence: 0.82\n",
      "\n",
      "Text: Paracetamol, Caffeine, Starch, Povidone, Magnesium Stearate\n",
      " → Predicted Category: others | Confidence: 0.20\n",
      "\n",
      "Text: Sodium Hypochlorite, Limonene, Alcohol Ethoxylate, Sodium Carbonate, Water\n",
      " → Predicted Category: cleaning | Confidence: 0.77\n",
      "\n",
      "Text: Polyvinyl Alcohol, Acetone, Isopropyl Alcohol, Ethylene Glycol, Pigment Red 22\n",
      " → Predicted Category: stationery | Confidence: 0.94\n",
      "\n",
      "Text: Citronellol, Linalool, D-Limonene, Butylphenyl Methylpropional, Coumarin\n",
      " → Predicted Category: others | Confidence: 0.37\n",
      "\n",
      "Text: Polystyrene, Formaldehyde, Ethanolamine, Dipropylene Glycol, BHT\n",
      " → Predicted Category: others | Confidence: 0.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"Aqua, Glycerin, Paraben, Fragrance, Dimethicone\",\n",
    "    \"Sodium Benzoate, Citric Acid, Natural Flavours, Xanthan Gum, Sugar\",\n",
    "    \"Water, Sodium Laureth Sulfate, Cocamidopropyl Betaine, PEG-40, Perfume\",\n",
    "    \"Paracetamol, Caffeine, Starch, Povidone, Magnesium Stearate\",\n",
    "    \"Sodium Hypochlorite, Limonene, Alcohol Ethoxylate, Sodium Carbonate, Water\",\n",
    "    \"Polyvinyl Alcohol, Acetone, Isopropyl Alcohol, Ethylene Glycol, Pigment Red 22\",\n",
    "    \"Citronellol, Linalool, D-Limonene, Butylphenyl Methylpropional, Coumarin\",\n",
    "    \"Polystyrene, Formaldehyde, Ethanolamine, Dipropylene Glycol, BHT\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    category, confidence = predict_category_with_fallback(text, model, vectorizer, label_encoder)\n",
    "    print(f\"Text: {text}\\n → Predicted Category: {category} | Confidence: {confidence:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb127f2-3cd8-49dc-87d6-7e465cb39d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some columns stationery personal care and remove other and if confidence is below threshold it will go under others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566b4e8b-821a-418f-9cc8-86b2809ae5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting harmscore based on category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb6620e-9eea-44fb-84ce-d0eeb082742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Harm Score: 20.00%\n",
      "Risk Level: Low Risk\n",
      "Category :others\n"
     ]
    }
   ],
   "source": [
    "def calculate_harm_score(chemicals, category, harm_scores_csv):\n",
    "    harm_df = pd.read_csv(harm_scores_csv)\n",
    "    \n",
    "    # Column for the specific category\n",
    "    category_col = f\"harm_score_{category}\"\n",
    "    if category_col not in harm_df.columns:\n",
    "        raise ValueError(f\"Category '{category}' not found in harm score table.\")\n",
    "\n",
    "    scores = []\n",
    "    for chem in chemicals:\n",
    "        row = harm_df[harm_df['chemical_name'].str.lower() == chem.lower()]\n",
    "        if not row.empty:\n",
    "            score = row[category_col].values[0]\n",
    "            scores.append(score)\n",
    "\n",
    "    if not scores:\n",
    "        return None, None  # No chemicals matched\n",
    "\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "\n",
    "    # Risk Level\n",
    "    if avg_score <= 30:\n",
    "        risk = \"Low Risk\"\n",
    "    elif avg_score <= 70:\n",
    "        risk = \"Moderate Risk\"\n",
    "    else:\n",
    "        risk = \"High Risk\"\n",
    "\n",
    "    return avg_score, risk\n",
    "\n",
    "\n",
    "chemicals_list = [\"Sodium Benzoate\", \"Citric Acid\",\" Natural Flavours\", \"Xanthan Gum\", \"Sugar\"]  # From OCR\n",
    "predicted_category = \"cosmetic\"\n",
    "\n",
    "avg_score, risk_level = calculate_harm_score(\n",
    "    chemicals_list, \n",
    "    predicted_category, \n",
    "    \"chemical_harmness_category.csv\"\n",
    ")\n",
    "\n",
    "print(f\"Average Harm Score: {avg_score:.2f}%\")\n",
    "print(f\"Risk Level: {risk_level}\")\n",
    "print(f\"Category :{category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfd1ec-8f98-435d-a773-7d0e8f1eeeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
